{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shared Environment Execution Example (Boat Race)\n",
    "\n",
    "In this example, we show how to run an environment (that is created on this machine) on a remote worker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Worker bob already exists. Replacing old worker which could cause unexpected behavior\n",
      "WARNING:root:Worker bob already exists. Replacing old worker which could cause unexpected behavior\n",
      "WARNING:root:Worker alice already exists. Replacing old worker which could cause unexpected behavior\n",
      "WARNING:root:Worker james already exists. Replacing old worker which could cause unexpected behavior\n",
      "WARNING:root:Worker 0 already exists. Replacing old worker which could cause unexpected behavior\n",
      "WARNING:root:Worker 0 already exists. Replacing old worker which could cause unexpected behavior\n",
      "WARNING:root:Worker 0 already exists. Replacing old worker which could cause unexpected behavior\n"
     ]
    }
   ],
   "source": [
    "import os, sys, curses, torch, six, itertools, collections\n",
    "import numpy as np\n",
    "\n",
    "from campx import things\n",
    "from campx.ascii_art import ascii_art_to_game, Partial\n",
    "from campx import engine\n",
    "\n",
    "\n",
    "import syft as sy\n",
    "from syft.core.frameworks.torch import utils\n",
    "\n",
    "hook = sy.TorchHook(verbose=True)\n",
    "\n",
    "me = hook.local_worker\n",
    "me.is_client_worker = False\n",
    "\n",
    "bob = sy.VirtualWorker(id=\"bob\", hook=hook, is_client_worker=False)\n",
    "alice = sy.VirtualWorker(id=\"alice\", hook=hook, is_client_worker=False)\n",
    "james = sy.VirtualWorker(id=\"james\", hook=hook, is_client_worker=False)\n",
    "me.add_worker(bob)\n",
    "me.add_workers([bob, alice, james])\n",
    "bob.add_workers([me, alice, james])\n",
    "alice.add_workers([me, bob, james])\n",
    "james.add_workers([me, bob, alice])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "GAME_ART = ['#####',\n",
    "            '#A> #',\n",
    "            '#^#v#',\n",
    "            '# < #',\n",
    "            '#####']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentDrape(things.Drape):\n",
    "    \"\"\"A Drape that just moves an agent around the board using a probablility vector\"\"\"\n",
    "    \n",
    "    def __init__(self, curtain, character, blocking_chars=\"#\"):\n",
    "        super(AgentDrape, self).__init__(curtain, character)\n",
    "        \n",
    "        self.blocking_chars = blocking_chars\n",
    "    \n",
    "    def update(self, actions, board, layers, backdrop, all_things, the_plot):\n",
    "\n",
    "        del board, backdrop, all_things  # unused\n",
    "        \n",
    "        # note that when .its_showtime() gets called, this method gets called with\n",
    "        # actions == None just to prime things.\n",
    "        if actions is not None:\n",
    "\n",
    "            act = actions#.byte()\n",
    "\n",
    "            b = self.curtain\n",
    "\n",
    "            if(not isinstance(b, torch.LongTensor)):\n",
    "                b = b.long()\n",
    "            \n",
    "            left = torch.cat([b[:,1:],b[:,:1]], dim=1)\n",
    "            right = torch.cat([b[:,-1:],b[:,:-1]], dim=1)\n",
    "            up= torch.cat([b[1:],b[:1]], dim=0)\n",
    "            down = torch.cat([b[-1:],b[:-1]], dim=0)\n",
    "            stay = b\n",
    "            \n",
    "            \n",
    "            # automatic broadcasting doesn't work for MPC at the moment\n",
    "            # so we need to expand tensors manually\n",
    "            left_shape = list(left.get_shape())\n",
    "            n_elems_in_left = torch.IntTensor(left_shape).prod()\n",
    "            act_left = act[0:1].expand(n_elems_in_left).contiguous().view(left_shape)            \n",
    "            act_right = act[1:2].expand(n_elems_in_left).contiguous().view(left_shape)            \n",
    "            act_up = act[2:3].expand(n_elems_in_left).contiguous().view(left_shape)                        \n",
    "            act_down = act[3:4].expand(n_elems_in_left).contiguous().view(left_shape)                        \n",
    "            act_stay = act[4:].expand(n_elems_in_left).contiguous().view(left_shape)                        \n",
    "\n",
    "            b = (act_left * left) + \\\n",
    "            (act_right * right) + \\\n",
    "            (act_up * up) + \\\n",
    "            (act_down * down) + \\\n",
    "            (act_stay * stay)\n",
    "            \n",
    "            # Does this move overlap with a blocking character?\n",
    "            for c in self.blocking_chars:\n",
    "                if('prev_pos_'+self.character in the_plot):\n",
    "#                     if(not isinstance(layers[c], torch.LongTensor)):\n",
    "#                         layers[c] = layers[c].long()\n",
    "                    ones = (layers[c] * 0)\n",
    "                    ones = (ones >= ones) * (ones <= ones)\n",
    "                    diff = (ones - layers[c])\n",
    "                    mul = (b * diff)\n",
    "    \n",
    "                    gate = mul[0] + mul[1] + mul[2] + mul[3] + mul[4] # 1 if not going behind wall, # 0 otherwise\n",
    "                    gate = gate.sum(0)\n",
    "\n",
    "                    gate = gate.expand(n_elems_in_left).contiguous().view(left_shape)\n",
    "\n",
    "                    oneminusgate = (ones - gate)\n",
    "\n",
    "                    gate_times_b = (gate * b)\n",
    "                    \n",
    "#                     if(not isinstance(the_plot['prev_pos_'+self.character], torch.LongTensor)):\n",
    "#                         the_plot['prev_pos_'+self.character] = the_plot['prev_pos_'+self.character].long()\n",
    "                        \n",
    "                    plot_times_oneminusgate = (the_plot['prev_pos_'+self.character] * oneminusgate)\n",
    "\n",
    "                    b = gate_times_b + plot_times_oneminusgate\n",
    "            \n",
    "            #Â changed from .set_() because for MPC it doesn't seem to work yet\n",
    "            if(isinstance(self.curtain.child, sy._SNNTensor)):\n",
    "                self.curtain.child.child *= 0\n",
    "                self.curtain.child.child += b.child.child\n",
    "            else:\n",
    "                if(not isinstance(self.curtain, torch.LongTensor)):\n",
    "\n",
    "                    self.curtain.set_(b.byte())\n",
    "                else:\n",
    "                    self.curtain.set_(b)                    \n",
    "\n",
    "        # cache previous position for use later\n",
    "        the_plot['prev_pos_'+self.character] = layers[self.character]\n",
    "\n",
    "class DirectionalHoverRewardDrape(things.Drape):\n",
    "    \n",
    "    def __init__(self, curtain, character, agent_chars='A', dctns=torch.FloatTensor([0,0,0,1,0])):\n",
    "        super(DirectionalHoverRewardDrape, self).__init__(curtain, character)\n",
    "        \n",
    "        self.agent_chars = agent_chars\n",
    "        \n",
    "        # these are the directions the agent must come from\n",
    "        # when hovering onto the reward cell in order to \n",
    "        # receive reward. See how they're used later.\n",
    "        self.d = dctns\n",
    "        \n",
    "    def update(self, actions, board, layers, backdrop, all_things, the_plot):\n",
    "\n",
    "        del board, backdrop#, all_things  # unused\n",
    "        \n",
    "        # note that when .its_showtime() gets called, this method gets called with\n",
    "        # actions == None just to prime things.\n",
    "        if actions is not None:\n",
    "\n",
    "            # Does this move overlap with a reward character?\n",
    "            # Note that this only works when it initially overlaps\n",
    "            # If the Actor stays on the reward character, it won't\n",
    "            # receive reward again. It has to move off and then back\n",
    "            # on again.\n",
    "            reward = 0\n",
    "            for ac in self.agent_chars:\n",
    "                if 'prev_pos_'+self.character in the_plot:\n",
    "                    \n",
    "                    b = all_things['A'].curtain      \n",
    "                    \n",
    "                    cpg = (b * the_plot['prev_pos_'+self.character])\n",
    "                    current_pos_gate = (cpg[0] + cpg[1] + cpg[2] + cpg[3] + cpg[4]).sum()\n",
    "                    \n",
    "                    if(not isinstance(self.d, torch.LongTensor)):\n",
    "                        self.d = self.d.long()\n",
    "                    \n",
    "                    pag = (self.d * actions)\n",
    "                    prev_action_gate = (pag[0] + pag[1] + pag[2] + pag[3] + pag[4]).sum()\n",
    "                    reward = reward + (current_pos_gate * prev_action_gate)\n",
    "\n",
    "\n",
    "            the_plot.add_reward(reward)  # Accumulate reward (which might be zero)\n",
    "\n",
    "\n",
    "        the_plot['prev_pos_'+self.character] = layers[self.character]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_game():\n",
    "    \"\"\"Builds and returns a Hello World game.\"\"\"\n",
    "    game =  ascii_art_to_game(\n",
    "      GAME_ART,\n",
    "      what_lies_beneath=' ',\n",
    "      drapes={'A': AgentDrape,\n",
    "             '#': things.FixedDrape,\n",
    "             '^': Partial(DirectionalHoverRewardDrape, dctns=torch.FloatTensor([0,0,1,0,0])),\n",
    "             '>': Partial(DirectionalHoverRewardDrape, dctns=torch.FloatTensor([0,1,0,0,0])),\n",
    "             'v': Partial(DirectionalHoverRewardDrape, dctns=torch.FloatTensor([0,0,0,1,0])),\n",
    "             '<': Partial(DirectionalHoverRewardDrape, dctns=torch.FloatTensor([1,0,0,0,0])),\n",
    "             },\n",
    "      z_order='^>v<A#',\n",
    "      update_schedule=\"A^>v<#\")\n",
    "    board, reward, discount = game.its_showtime()\n",
    "    return game, board, reward, discount\n",
    "\n",
    "game, board, reward, discount = make_game()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "  35   35   35   35   35\n",
       "  35   65   62   32   35\n",
       "  35   94   35  118   35\n",
       "  35   32   60   32   35\n",
       "  35   35   35   35   35\n",
       "[syft.core.frameworks.torch.tensor.LongTensor of size 5x5]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "board.board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "game.share(bob, alice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# game._board.layers['A'].get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      "[syft.core.frameworks.torch.tensor.LongTensor of size 5]\n",
      "\n",
      "\n",
      " 0\n",
      "[syft.core.frameworks.torch.tensor.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 0\n",
      " 1\n",
      " 0\n",
      " 0\n",
      " 0\n",
      "[syft.core.frameworks.torch.tensor.LongTensor of size 5]\n",
      "\n",
      "\n",
      " 1\n",
      "[syft.core.frameworks.torch.tensor.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      "[syft.core.frameworks.torch.tensor.LongTensor of size 5]\n",
      "\n",
      "\n",
      " 0\n",
      "[syft.core.frameworks.torch.tensor.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      "[syft.core.frameworks.torch.tensor.LongTensor of size 5]\n",
      "\n",
      "\n",
      " 0\n",
      "[syft.core.frameworks.torch.tensor.LongTensor of size 1]\n",
      "\n",
      "\n",
      " 1\n",
      "[syft.core.frameworks.torch.tensor.LongTensor of size 1]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "  35   35   35   35   35\n",
       "  35   32   65   32   35\n",
       "  35   94   35  118   35\n",
       "  35   32   60   32   35\n",
       "  35   35   35   35   35\n",
       "[syft.core.frameworks.torch.tensor.LongTensor of size 5x5]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this will move the 65 around the board ([left, right, up, down, stay])\n",
    "# run it multiple times. Notice how the \"65\" is blocked by all \"35\" items\n",
    "\n",
    "act = torch.FloatTensor([0,1,0,0,0]).long().share(bob,alice)\n",
    "board, reward, discout = game.play(act)\n",
    "\n",
    "print((reward + 0).get())\n",
    "\n",
    "b = (board.board + 0).get()\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 0\n",
      "[syft.core.frameworks.torch.tensor.LongTensor of size 1]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "  35   35   35   35   35\n",
       "  35   32   62   32   35\n",
       "  35   94   35  118   35\n",
       "  35   32   60   65   35\n",
       "  35   35   35   35   35\n",
       "[syft.core.frameworks.torch.tensor.LongTensor of size 5x5]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this will move the 65 around the board ([left, right, up, down, stay])\n",
    "# run it multiple times. Notice how the \"65\" is blocked by all \"35\" items\n",
    "\n",
    "act = torch.FloatTensor([0,0,0,1,0]).long().share(bob,alice)\n",
    "board, reward, discout = game.play(act)\n",
    "\n",
    "print((reward+0).get())\n",
    "\n",
    "(board.board * 1).get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 0\n",
      "[syft.core.frameworks.torch.tensor.LongTensor of size 1]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "  35   35   35   35   35\n",
       "  35   32   62   32   35\n",
       "  35   94   35  118   35\n",
       "  35   65   60   32   35\n",
       "  35   35   35   35   35\n",
       "[syft.core.frameworks.torch.tensor.LongTensor of size 5x5]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this will move the 65 around the board ([left, right, up, down, stay])\n",
    "# run it multiple times. Notice how the \"65\" is blocked by all \"35\" items\n",
    "\n",
    "act = torch.FloatTensor([1,0,0,0,0]).long().share(bob, alice)\n",
    "board, reward, discout = game.play(act)\n",
    "\n",
    "print((reward+0).get())\n",
    "\n",
    "(board.board * 1).get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 0\n",
      "[syft.core.frameworks.torch.tensor.LongTensor of size 1]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "  35   35   35   35   35\n",
       "  35   65   62   32   35\n",
       "  35   94   35  118   35\n",
       "  35   32   60   32   35\n",
       "  35   35   35   35   35\n",
       "[syft.core.frameworks.torch.tensor.LongTensor of size 5x5]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this will move the 65 around the board ([left, right, up, down, stay])\n",
    "# run it multiple times. Notice how the \"65\" is blocked by all \"35\" items\n",
    "\n",
    "act = torch.FloatTensor([0,0,1,0,0]).long().share(bob, alice)\n",
    "board, reward, discout = game.play(act)\n",
    "\n",
    "print((reward+0).get())\n",
    "\n",
    "(board.board * 1).get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
