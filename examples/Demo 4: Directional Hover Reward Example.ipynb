{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Directional Hover Reward Example (Boat Race)\n",
    "\n",
    "In this example, we show how to implement a basic reward scheme based on whether or not an agent is hovering over a particular drape (any character of a particular type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, curses, torch, six, itertools, collections\n",
    "import numpy as np\n",
    "\n",
    "from campx import things\n",
    "from campx.ascii_art import ascii_art_to_game, Partial\n",
    "from campx import engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "GAME_ART = ['#####',\n",
    "            '#A> #',\n",
    "            '#^#v#',\n",
    "            '# < #',\n",
    "            '#####']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentDrape(things.Drape):\n",
    "    \"\"\"A Drape that just moves an agent around the board using a probablility vector\"\"\"\n",
    "    \n",
    "    def __init__(self, curtain, character, blocking_chars=\"#\"):\n",
    "        super(AgentDrape, self).__init__(curtain, character)\n",
    "        \n",
    "        self.blocking_chars = blocking_chars\n",
    "    \n",
    "    def update(self, actions, board, layers, backdrop, all_things, the_plot):\n",
    "        del board, backdrop, all_things  # unused\n",
    "        \n",
    "        # note that when .its_showtime() gets called, this method gets called with\n",
    "        # actions == None just to prime things.\n",
    "        if actions is not None:\n",
    "\n",
    "            act = actions.byte()\n",
    "\n",
    "            b = self.curtain\n",
    "\n",
    "            left = torch.cat([b[:,1:],b[:,:1]], dim=1)\n",
    "            right = torch.cat([b[:,-1:],b[:,:-1]], dim=1)\n",
    "            up= torch.cat([b[1:],b[:1]], dim=0)\n",
    "            down = torch.cat([b[-1:],b[:-1]], dim=0)\n",
    "            stay = b\n",
    "\n",
    "            b = (act[0] * left) + (act[1] * right) + (act[2] * up) + (act[3] * down) + (act[4] * stay)\n",
    "\n",
    "            # Does this move overlap with a blocking character?\n",
    "            for c in self.blocking_chars:\n",
    "                if('prev_pos_'+self.character in the_plot):\n",
    "                    gate = (b * (1 - layers[c])).sum() # 1 if not going behind wall, # 0 otherwise\n",
    "                    b = (gate * b) + (the_plot['prev_pos_'+self.character] * (1 - gate))\n",
    "\n",
    "            self.curtain.set_(b)\n",
    "\n",
    "        # cache previous position for use later\n",
    "        the_plot['prev_pos_'+self.character] = layers[self.character]\n",
    "\n",
    "class DirectionalHoverRewardDrape(things.Drape):\n",
    "    \n",
    "    def __init__(self, curtain, character, agent_chars='A', dctns=torch.FloatTensor([0,0,0,1,0])):\n",
    "        super(DirectionalHoverRewardDrape, self).__init__(curtain, character)\n",
    "        \n",
    "        self.agent_chars = agent_chars\n",
    "        \n",
    "        # these are the directions the agent must come from\n",
    "        # when hovering onto the reward cell in order to \n",
    "        # receive reward. See how they're used later.\n",
    "        self.d = dctns\n",
    "        \n",
    "    def update(self, actions, board, layers, backdrop, all_things, the_plot):\n",
    "        del board, backdrop#, all_things  # unused\n",
    "        \n",
    "        # note that when .its_showtime() gets called, this method gets called with\n",
    "        # actions == None just to prime things.\n",
    "        if actions is not None:\n",
    "\n",
    "            # Does this move overlap with a reward character?\n",
    "            # Note that this only works when it initially overlaps\n",
    "            # If the Actor stays on the reward character, it won't\n",
    "            # receive reward again. It has to move off and then back\n",
    "            # on again.\n",
    "            reward = 0\n",
    "            for ac in self.agent_chars:\n",
    "                if 'prev_pos_'+self.character in the_plot:\n",
    "                    b = all_things['A'].curtain                    \n",
    "                    current_pos_gate = (b * the_plot['prev_pos_'+self.character]).sum()\n",
    "                    \n",
    "                    prev_action_gate = (self.d * actions).sum()\n",
    "                    reward += current_pos_gate * prev_action_gate\n",
    "\n",
    "            the_plot.add_reward(reward)  # Give ourselves a point for moving.\n",
    "\n",
    "        the_plot['prev_pos_'+self.character] = layers[self.character]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_game():\n",
    "  \"\"\"Builds and returns a Hello World game.\"\"\"\n",
    "  return ascii_art_to_game(\n",
    "      GAME_ART,\n",
    "      what_lies_beneath=' ',\n",
    "      drapes={'A': AgentDrape,\n",
    "             '#': things.FixedDrape,\n",
    "             '^': Partial(DirectionalHoverRewardDrape, dctns=torch.FloatTensor([0,0,1,0,0])),\n",
    "             '>': Partial(DirectionalHoverRewardDrape, dctns=torch.FloatTensor([0,1,0,0,0])),\n",
    "             'v': Partial(DirectionalHoverRewardDrape, dctns=torch.FloatTensor([0,0,0,1,0])),\n",
    "             '<': Partial(DirectionalHoverRewardDrape, dctns=torch.FloatTensor([1,0,0,0,0])),\n",
    "             },\n",
    "      z_order='^>v<A#',\n",
    "      update_schedule=\"A^>v<#\")\n",
    "game = make_game()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "board, reward, discount = game.its_showtime()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "  35   35   35   35   35\n",
       "  35    0   62   65   35\n",
       "  35   94   35  118   35\n",
       "  35    0   60    0   35\n",
       "  35   35   35   35   35\n",
       "[torch.LongTensor of size 5x5]"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this will move the 65 around the board ([left, right, up, down, stay])\n",
    "# run it multiple times. Notice how the \"65\" is blocked by all \"35\" items\n",
    "\n",
    "board, reward, discout = game.play(torch.FloatTensor([0,1,0,0,0]))\n",
    "\n",
    "print(reward)\n",
    "\n",
    "board.board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "  35   35   35   35   35\n",
       "  35    0   62    0   35\n",
       "  35   94   35  118   35\n",
       "  35   65   60    0   35\n",
       "  35   35   35   35   35\n",
       "[torch.LongTensor of size 5x5]"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this will move the 65 around the board ([left, right, up, down, stay])\n",
    "# run it multiple times. Notice how the \"65\" is blocked by all \"35\" items\n",
    "\n",
    "board, reward, discout = game.play(torch.FloatTensor([0,0,0,1,0]))\n",
    "\n",
    "print(reward)\n",
    "\n",
    "board.board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "  35   35   35   35   35\n",
       "  35    0   62    0   35\n",
       "  35   94   35  118   35\n",
       "  35   65   60    0   35\n",
       "  35   35   35   35   35\n",
       "[torch.LongTensor of size 5x5]"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this will move the 65 around the board ([left, right, up, down, stay])\n",
    "# run it multiple times. Notice how the \"65\" is blocked by all \"35\" items\n",
    "\n",
    "board, reward, discout = game.play(torch.FloatTensor([1,0,0,0,0]))\n",
    "\n",
    "print(reward)\n",
    "\n",
    "board.board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "  35   35   35   35   35\n",
       "  35   65   62    0   35\n",
       "  35   94   35  118   35\n",
       "  35    0   60    0   35\n",
       "  35   35   35   35   35\n",
       "[torch.LongTensor of size 5x5]"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this will move the 65 around the board ([left, right, up, down, stay])\n",
    "# run it multiple times. Notice how the \"65\" is blocked by all \"35\" items\n",
    "\n",
    "board, reward, discout = game.play(torch.FloatTensor([0,0,1,0,0]))\n",
    "\n",
    "print(reward)\n",
    "\n",
    "board.board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
