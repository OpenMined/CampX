{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Agent Example\n",
    "\n",
    "I this example, we show how to create a small world with a single (Drape) agent which can walk around. Note that the update only uses addition and multiplication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, curses, torch, six, itertools, collections\n",
    "import numpy as np\n",
    "\n",
    "from campx import things\n",
    "from campx.ascii_art import ascii_art_to_game, Partial\n",
    "from campx import engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "GAME_ART = ['#####',\n",
    "             '#A* #',\n",
    "             '#*#*#',\n",
    "             '# * #',\n",
    "             '#####']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentDrape(things.Drape):\n",
    "    \"\"\"A Drape that just moves an agent around the board using a probablility vector\"\"\"\n",
    "\n",
    "    def update(self, actions, board, layers, backdrop, all_things, the_plot):\n",
    "        del board, layers, backdrop, all_things  # unused\n",
    "\n",
    "        if actions is None: return  # No work needed to make the first observation.\n",
    "        \n",
    "        act = actions\n",
    "        \n",
    "        b = self.curtain\n",
    "        \n",
    "        left = torch.cat([b[:,1:],b[:,:1]], dim=1)\n",
    "        right = torch.cat([b[:,-1:],b[:,:-1]], dim=1)\n",
    "        up= torch.cat([b[1:],b[:1]], dim=0)\n",
    "        down = torch.cat([b[-1:],b[:-1]], dim=0)\n",
    "        stay = b\n",
    "\n",
    "        b = (act[0] * left) + (act[1] * right) + (act[2] * up) + (act[3] * down) + (act[4] * stay)\n",
    "        self.curtain.set_(b)\n",
    "        \n",
    "        the_plot.add_reward(1)  # Give ourselves a point for moving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_game():\n",
    "  \"\"\"Builds and returns a Hello World game.\"\"\"\n",
    "  return ascii_art_to_game(\n",
    "      GAME_ART,\n",
    "      what_lies_beneath=' ',\n",
    "      drapes={'A': AgentDrape},\n",
    "      z_order='A')\n",
    "game = make_game()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "board, reward, discount = game.its_showtime()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "  0   0   0   0   0\n",
       " 65   0   0   0   0\n",
       "  0   0   0   0   0\n",
       "  0   0   0   0   0\n",
       "  0   0   0   0   0\n",
       "[torch.LongTensor of size 5x5]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this will move the 65 around the board ([left, right, up, down, stay])\n",
    "\n",
    "board, reward, discout = game.play([1,0,0,0,0])\n",
    "\n",
    "board.board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "game._the_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "(0 ,.,.) = \n",
       "  0  0  0  0  0\n",
       "  0  0  0  0  0\n",
       "  0  0  0  0  0\n",
       "  0  0  0  0  0\n",
       "  0  0  0  0  0\n",
       "\n",
       "(1 ,.,.) = \n",
       "  0  0  0  0  0\n",
       "  0  0  0  0  0\n",
       "  0  0  0  0  0\n",
       "  0  0  0  0  0\n",
       "  0  0  0  0  0\n",
       "\n",
       "(2 ,.,.) = \n",
       "  0  0  0  0  0\n",
       "  0  0  0  0  0\n",
       "  0  0  0  0  0\n",
       "  0  0  0  0  0\n",
       "  0  0  0  0  0\n",
       "\n",
       "(3 ,.,.) = \n",
       "  0  0  0  0  0\n",
       "  1  0  0  0  0\n",
       "  0  0  0  0  0\n",
       "  0  0  0  0  0\n",
       "  0  0  0  0  0\n",
       "[torch.LongTensor of size 4x5x5]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is what you'd use as input for the agent\n",
    "board.layered_board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
