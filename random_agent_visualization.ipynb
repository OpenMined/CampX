{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "from EnvCatcher import EnvCatcher\n",
    "from IPython import display\n",
    "from matplotlib import pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set experimental parameters\n",
    "max_num_episodes = 10\n",
    "max_num_steps = 100\n",
    "# can set a random seed for consistency in agent AND environment\n",
    "random_seed = None\n",
    "if random_seed is not None:\n",
    "    np.random.seed(random_seed)\n",
    "frame = 0\n",
    "#translate the actions to human readable words\n",
    "action_space = [\"Left\",\"Stay\",\"Right\"]\n",
    "#size of the game field\n",
    "grid_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graphics(action,ep_reward,observation):\n",
    "    global frame\n",
    "    print(\"ep: {}, steps: {}, ep_reward_total: {}\".format(i_episode, t+1, ep_reward))\n",
    "    if(\"End\" not in action_space[action]):\n",
    "        plt.imshow(observation.reshape((grid_size,)*2),\n",
    "               interpolation='none', cmap='gray')\n",
    "        display.clear_output(wait=True)\n",
    "        display.display(plt.gcf())\n",
    "    frame = fps(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fps(last_frame_time,FPS = 1):\n",
    "    current_milli_time = lambda: int(round(time.time() * 1000))\n",
    "    sleep_time = 1./FPS - (current_milli_time() - last_frame_time)\n",
    "    if sleep_time > 0:\n",
    "        time.sleep(sleep_time)\n",
    "    return current_milli_time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = EnvCatcher(grid_size=10, env_type='episodic', verbose=False, \n",
    "                 max_num_steps=100, random_seed=random_seed)\n",
    "\n",
    "total_reward_by_episode = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPgAAAD8CAYAAABaQGkdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nY/8G1PskEIg9MlAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x103dfaf60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep: 9, steps: 9, ep_reward_total: -1\n"
     ]
    }
   ],
   "source": [
    "for i_episode in range(max_num_episodes):\n",
    "    # for each episode reset the environment and the episode reward\n",
    "    observation = env.reset()\n",
    "    ep_reward = 0\n",
    "    # perform the episode for the max number of steps\n",
    "    for t in range(max_num_steps):\n",
    "        # random action policy\n",
    "        action = np.random.randint(env.action_space)\n",
    "        # take action in environment\n",
    "        observation, reward, done, info = env.step(action)\n",
    "        # accumulate reward\n",
    "        ep_reward += reward\n",
    "        graphics(action,ep_reward,observation)\n",
    "        # environment will provide a done flag, learning should handle it\n",
    "        if done:\n",
    "            print(\"ep: {}, steps: {}, ep_reward_total: {}\".format(i_episode, t+1, \n",
    "                  ep_reward))\n",
    "            total_reward_by_episode.append(ep_reward)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode rewards [-1, 1, -1, 1, -1, 1, 1, 1, 1, 1]\n",
      "sum of episode rewards 4\n",
      "average episodic reward 0.4\n"
     ]
    }
   ],
   "source": [
    "print('episode rewards', total_reward_by_episode)\n",
    "print('sum of episode rewards', np.sum(total_reward_by_episode))\n",
    "print('average episodic reward', np.sum(total_reward_by_episode)/float(len(total_reward_by_episode)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
